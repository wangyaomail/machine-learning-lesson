# 决策树
## 请对比叙述ID3、C4.5、CART三个模型之间的联系、区别和适用性。
答案：
1)	联系：这三个模型都是决策树模型，他们的基本计算逻辑一致，只在进行分支判断的地方不同。
2)	区别：ID3和C4.5基于信息增益（或信息熵）计算，CART基于基尼系数计算。C4.5是ID3的升级版，能够避免ID3对编号类特征的过拟合。
3)	适用性：ID3和C4.5适合真实场景下的数据，CART适合抽象场景下的数据。
## 什么是决策树的剪枝策略？剪枝的作用是什么？
答案：
1)	决策树的某层节点数过多的时候，可以对决策树某些结点进行剪枝，删掉不需要的决策树分支。
2)	剪枝的好处是能够降低模型复杂性，避免对学习算法过拟合。
## 什么是决策树的预剪枝和后剪枝？哪种剪枝策略生成的树更深？哪种剪枝策略训练资源消耗更大？
答案：
1)	预剪枝：在决策树生成过程中每一轮划分后剪枝。
2)	后剪枝：在决策树生成完毕后，回过头剪枝。
3)	从深度上说，后剪枝生成的决策树更深。
4)	从训练资源消耗上说，后剪枝资源消耗更大。